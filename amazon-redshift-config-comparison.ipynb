{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96c76b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILE_S3_URI=\"<< S3 LOCATION URI FOR CONFIGURATION JSON FILE >>\"\n",
    "RS_HOST = '<< YOUR REDSHIFT CLUSTER ENDPOINT >>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7cfc2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlalchemy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (1.3.23)\n",
      "Requirement already satisfied: psycopg2-binary in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (2.9.1)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install sqlalchemy \n",
    "pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b284249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import psycopg2\n",
    "import time\n",
    "import pandas\n",
    "from sqlalchemy import create_engine\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from concurrent.futures import as_completed\n",
    "from urllib.parse import quote_plus as urlquote\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05a534be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_redshift(host,username):\n",
    "    client = boto3.client('redshift')\n",
    "    cluster_creds = client.get_cluster_credentials(DbUser=username,\n",
    "                                                   DbName=RS_HOST.split('/')[1],\n",
    "                                                   ClusterIdentifier=RS_HOST.split('.')[0])\n",
    "\n",
    "\n",
    "    connection_string='postgresql://'+ urlquote(cluster_creds['DbUser']) + ':'+ urlquote(cluster_creds['DbPassword']) + '@'+ RS_HOST\n",
    "    return create_engine(connection_string)\n",
    "\n",
    "def get_json_config_from_s3(script_s3_path):\n",
    "    bucket, key = script_s3_path.replace(\"s3://\", \"\").split(\"/\", 1)\n",
    "    obj = boto3.client('s3').get_object(Bucket=bucket, Key=key)\n",
    "    return json.loads(obj['Body'].read().decode('utf-8'))\n",
    "\n",
    "\n",
    "def get_concurrency_scripts_from_s3(cluster_identifier,config_json,number_of_parallel_sessions):\n",
    "    script_s3_path = config_json.get('concurrent_user_queries_and_load_s3_path')\n",
    "    redshift_iam_role = config_json.get('redshift_iam_role')\n",
    "    bucket_name = config_json.get('s3_bucket_name')\n",
    "                           \n",
    "    bucket, key = script_s3_path.replace(\"s3://\", \"\").split(\"/\", 1)\n",
    "    obj = boto3.client('s3').get_object(Bucket=bucket, Key=key)\n",
    "    scripts = obj['Body'].read().decode('utf-8')\n",
    "    scripts = scripts.format(redshift_iam_role=redshift_iam_role, bucket_name=bucket_name,cluster_identifier=cluster_identifier)\n",
    "    split_scripts = scripts.split(';')[:-1]\n",
    "    if len(split_scripts) < number_of_parallel_sessions:\n",
    "        while len(split_scripts) < number_of_parallel_sessions:\n",
    "            split_scripts.extend(split_scripts)\n",
    "    return split_scripts\n",
    "\n",
    "\n",
    "def get_sql(engine, script, sequence_number):\n",
    "    df = None\n",
    "    sql = \"set enable_result_cache_for_session to false;\" + script[sequence_number];\n",
    "    df = pandas.read_sql(sql, engine)\n",
    "    return df\n",
    "\n",
    "\n",
    "def run_concurrency_test(number_of_parallel_sessions): \n",
    "    config = get_json_config_from_s3(CONFIG_FILE_S3_URI)\n",
    "    engine=connect_to_redshift(RS_HOST,config.get('master_user_name'))\n",
    "    script = get_concurrency_scripts_from_s3(RS_HOST.split('.')[0],config, number_of_parallel_sessions)\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        with ThreadPoolExecutor(max_workers=number_of_parallel_sessions) as executor:\n",
    "            futures = []\n",
    "            for sequence_number in range(number_of_parallel_sessions):\n",
    "                futures.append(executor.submit(\n",
    "                    get_sql, engine, script, sequence_number))\n",
    "            for future in as_completed(futures):\n",
    "                rs = future.result()\n",
    "\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "    elapsed_time_in_secs = (time.time() - start_time)\n",
    "    print(\"--- %s seconds ---\" % elapsed_time_in_secs)\n",
    "    return elapsed_time_in_secs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15021c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running 1 parallel threads ..\n",
      "--- 15.19753122329712 seconds ---\n",
      "--- 15.018664836883545 seconds ---\n",
      "--- 14.543593883514404 seconds ---\n",
      "--- 16.660288095474243 seconds ---\n",
      "--- 15.54794955253601 seconds ---\n",
      "average of five runs with 1 parallel sessions: 15.393605518341065\n",
      "running 20 parallel threads ..\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################\n",
    "# Please input the desired parallel threads below. By default, it runs five times with 1, 20, 40, 50 threads\n",
    "# Average of 5 runs of concurrency testing is taken as the final outcome.\n",
    "################################################################################################################\n",
    "for number_of_parallel_sessions in [1,20,40,50]:\n",
    "    print(\"running %s parallel threads ..\" % number_of_parallel_sessions)\n",
    "    tm = []\n",
    "    # try 5 times for each thread count\n",
    "    for j in range(0, 5):\n",
    "        tm.append(run_concurrency_test(number_of_parallel_sessions))\n",
    "    avg = sum(tm)/len(tm)\n",
    "    print(f\"average of five runs with {number_of_parallel_sessions} parallel sessions: {avg}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
